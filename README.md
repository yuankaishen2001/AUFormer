# AUFormer
[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/auformer-vision-transformers-are-parameter/facial-action-unit-detection-on-bp4d)](https://paperswithcode.com/sota/facial-action-unit-detection-on-bp4d?p=auformer-vision-transformers-are-parameter)
[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/auformer-vision-transformers-are-parameter/facial-action-unit-detection-on-disfa)](https://paperswithcode.com/sota/facial-action-unit-detection-on-disfa?p=auformer-vision-transformers-are-parameter)

The official code for the paper _'AUFormer: Vision Transformers are Parameter-Efficient Facial Action Unit Detectors'_.

## News
- **_News (2024-07)_**: 🎉🎉🎉 Congratulations on AUFormer being accepted by ECCV 2024🔥! Our open-source code is making progress, stay tuned for updates!


<p align="center">
<img src="Pipeline.png" width="100%" />
</p>

**The Pytorch code is coming soon!**

🎓 Citation
=
If you find this repository is useful, please consider star🌟 this repo and cite🖇️ our paper.
```
@article{yuan2024auformer,
  title={AUFormer: Vision Transformers are Parameter-Efficient Facial Action Unit Detectors},
  author={Yuan, Kaishen and Yu, Zitong and Liu, Xin and Xie, Weicheng and Yue, Huanjing and Yang, Jingyu},
  journal={arXiv preprint arXiv:2403.04697},
  year={2024}
}
```
